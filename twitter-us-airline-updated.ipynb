{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10222701,"sourceType":"datasetVersion","datasetId":6319643}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom transformers import RobertaModel, RobertaTokenizer, AdamW\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import resample\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ndataset_path = \"/kaggle/input/twitter-us-airline/Twitter_US_Airline/Tweets.csv\"\ndf = pd.read_csv(dataset_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isna() #returns True if value is missing and False if value is not missing","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isna().any() #same as isna() but it works in column level","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isna().sum() #count the number of missing values (NaNs) in each column","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fix random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Load and Preprocess Data\ndef clean_text(text):\n    import re\n    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n    text = re.sub(r\"@\\w+\", \"\", text)    # Remove mentions\n    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters\n    return text.strip().lower()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply text cleaning\ndf[\"clean_text\"] = df[\"text\"].apply(clean_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract cleaned texts and labels\ntexts = df[\"clean_text\"].tolist()\nlabels = df[\"airline_sentiment\"].map({\"negative\": 0, \"neutral\": 1, \"positive\": 2}).tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Oversample Data for Class Balancing\ndef oversample_data(texts, labels):\n    data = list(zip(texts, labels))\n    negative = [x for x in data if x[1] == 0]\n    neutral = [x for x in data if x[1] == 1]\n    positive = [x for x in data if x[1] == 2]\n\n    neutral_upsampled = resample(neutral, replace=True, n_samples=len(negative), random_state=42)\n    positive_upsampled = resample(positive, replace=True, n_samples=len(negative), random_state=42)\n\n    balanced_data = negative + neutral_upsampled + positive_upsampled\n    random.shuffle(balanced_data)\n    return zip(*balanced_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: Dataset Class\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        encoding = self.tokenizer(\n            self.texts[idx],\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        item = {key: val.squeeze(0) for key, val in encoding.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4: Attention Layer\nclass AttentionLayer(nn.Module):\n    def __init__(self, hidden_size):\n        super(AttentionLayer, self).__init__()\n        self.attention = nn.Linear(hidden_size, 1, bias=False)\n\n    def forward(self, rnn_output):\n        weights = torch.softmax(self.attention(rnn_output), dim=1)\n        weighted_output = torch.sum(weights * rnn_output, dim=1)\n        return weighted_output, weights","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 5: Base Model with RoBERTa + RNN + Attention\nclass RoBERTaRNNWithAttention(nn.Module):\n    def __init__(self, model_type=\"lstm\", hidden_size=128, num_classes=3):\n        super(RoBERTaRNNWithAttention, self).__init__()\n        self.roberta = RobertaModel.from_pretrained(\"roberta-large\")  # Use roberta-large\n        self.rnn_type = model_type.lower()\n        self.hidden_size = hidden_size\n\n        if self.rnn_type == \"lstm\":\n            self.rnn = nn.LSTM(self.roberta.config.hidden_size, hidden_size, batch_first=True, bidirectional=True)\n        elif self.rnn_type == \"bilstm\":\n            self.rnn = nn.LSTM(self.roberta.config.hidden_size, hidden_size, batch_first=True, bidirectional=True)\n        elif self.rnn_type == \"gru\":\n            self.rnn = nn.GRU(self.roberta.config.hidden_size, hidden_size, batch_first=True, bidirectional=True)\n        else:\n            raise ValueError(f\"Unsupported RNN type: {model_type}\")\n\n        self.attention = AttentionLayer(hidden_size * 2)  # Bidirectional doubles the size\n        self.fc = nn.Linear(hidden_size * 2, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        with torch.no_grad():  # Freeze RoBERTa during training\n            roberta_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state = roberta_output.last_hidden_state\n        rnn_output, _ = self.rnn(last_hidden_state)\n        attn_output, _ = self.attention(rnn_output)\n        logits = self.fc(attn_output)\n        return logits","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 6: Ensemble Model\nclass EnsembleModel(nn.Module):\n    def __init__(self, models):\n        super(EnsembleModel, self).__init__()\n        self.models = nn.ModuleList(models)\n        self.fc = nn.Linear(len(models) * 3, 3)  # For 3 classes (Negative, Neutral, Positive)\n\n    def forward(self, input_ids, attention_mask):\n        logits_list = [model(input_ids, attention_mask) for model in self.models]\n        logits = torch.cat(logits_list, dim=1)  # Concatenate logits\n        return self.fc(logits)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 7: Oversample and Create Dataset\nbalanced_texts, balanced_labels = oversample_data(texts, labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")  # Use roberta-large tokenizer\ndataset = SentimentDataset(balanced_texts, balanced_labels, tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split dataset\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize models\nlstm_model = RoBERTaRNNWithAttention(model_type=\"lstm\").to(device)\nbilstm_model = RoBERTaRNNWithAttention(model_type=\"bilstm\").to(device)\ngru_model = RoBERTaRNNWithAttention(model_type=\"gru\").to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ensemble_model = EnsembleModel([lstm_model, bilstm_model, gru_model]).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optimizer and loss\noptimizer = torch.optim.AdamW(ensemble_model.parameters(), lr=2e-5)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Early Stopping Setup\nbest_val_loss = float(\"inf\")\npatience = 5 # Allow more epochs before early stopping(Higher patience for more training epochs)\npatience_counter = 0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\nnum_epochs = 20\nfor epoch in range(num_epochs):\n    ensemble_model.train()\n    train_loss, train_correct = 0, 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        logits = ensemble_model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        train_correct += (logits.argmax(dim=1) == labels).sum().item()\n\n    train_loss /= len(train_loader)\n    train_accuracy = train_correct / len(train_dataset)\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n\n    ensemble_model.eval()\n    val_loss, val_correct = 0, 0\n    val_preds, val_labels = [], []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            logits = ensemble_model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n\n            val_loss += loss.item()\n            val_correct += (logits.argmax(dim=1) == labels).sum().item()\n            val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n\n    val_loss /= len(val_loader)\n    val_accuracy = val_correct / len(val_dataset)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n\n    # Early Stopping Check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n        # Save best model\n        torch.save(ensemble_model.state_dict(), \"best_ensemble_model.pth\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping triggered.\")\n            break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classification report\nprint(classification_report(val_labels, val_preds, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting Graphs\nepochs_range = range(1, len(train_losses) + 1)\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, train_losses, label=\"Train Loss\")\nplt.plot(epochs_range, val_losses, label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Across Epochs\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, train_accuracies, label=\"Train Accuracy\")\nplt.plot(epochs_range, val_accuracies, label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy Across Epochs\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final Graph\nplt.figure(figsize=(8, 6))\nplt.plot(epochs_range, train_losses, label=\"Train Loss\")\nplt.plot(epochs_range, val_losses, label=\"Validation Loss\")\nplt.plot(epochs_range, train_accuracies, label=\"Train Accuracy\")\nplt.plot(epochs_range, val_accuracies, label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Metrics\")\nplt.title(\"Training and Validation Metrics\")\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}